---
title: "Gradient-Type Methods"
date: 2011-01-01
publishDate: 2020-12-23T16:51:07.052986Z
authors: ["Foad Mahdavi Pajouh", "Balabhaskar Balasundaram"]
publication_types: ["6"]
abstract: "The gradient method , which is also called the method of steepest descent, and the Cauchy method, is one of the most fundamental derivative‚Äêbased procedure for unconstrained minimization of a differentiable function. The performance of the method in terms of speed of convergence is lacking, and it tends to suffer from very slow convergence, especially as a stationary point is approached. However, it does guarantee global convergence under reasonable conditions and admits a thorough mathematical analysis of its behavior. For this reason, the gradient method has been used as a starting point in the development of more sophisticated, globally convergent algorithms with better convergence properties for unconstrained minimization. This article presents a cogent overview of this fundamental method and its convergence properties under various settings."
featured: false
publication: "*Wiley Encyclopedia of Operations Research and Management Science*"
tags: ["unconstrained optimization", "gradient method", "method of steepest descent", "Cauchy method", "subgradient method"]
url_pdf: "http://dx.doi.org/10.1002/9780470400531.eorms0363"
doi: "10.1002/9780470400531.eorms0363"
---

