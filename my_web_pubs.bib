%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Baski Balasundaram at 2020-12-23 10:53:14 -0600 


%% Saved with string encoding Unicode (UTF-8) 



@article{farmanesh2020calibration,
	abstract = {We study statistical calibration, i.e., adjusting features of a computational model that are not observable or controllable in its associated physical system. We focus on functional calibration, which arises in many manufacturing processes where the unobservable features, called calibration variables, are a function of the input variables. A major challenge in many applications is that computational models are expensive and can only be evaluated a limited number of times. Furthermore, without making strong assumptions, the calibration variables are not identifiable. We propose Bayesian Non-isometric Matching Calibration (BNMC) that allows calibration of expensive computational models with only a limited number of samples taken from a computational model and its associated physical system. BNMC replaces the computational model with a dynamic Gaussian process whose parameters are trained in the calibration procedure. To resolve the identifiability issue, we present the calibration problem from a geometric perspective of non-isometric curve to surface matching, which enables us to take advantage of combinatorial optimization techniques to extract necessary information for constructing prior distributions. Our numerical experiments demonstrate that in terms of prediction accuracy BNMC outperforms, or is comparable to, other existing calibration frameworks.},
	author = {Babak Farmanesh and Arash Pourhabib and Balabhaskar Balasundaram and Austin Buchanan},
	date-added = {2020-12-10 08:48:13 -0600},
	date-modified = {2020-12-12 08:29:55 -0600},
	doi = {10.1080/24725854.2020.1774688},
	eprint = {https://doi.org/10.1080/24725854.2020.1774688},
	journal = {IISE Transactions},
	month = {March},
	number = {3},
	pages = {352--364},
	publisher = {Taylor & Francis},
	title = {A {Bayesian} framework for functional calibration of expensive computational models through non-isometric matching},
	url = {https://doi.org/10.1080/24725854.2020.1774688},
	volume = {53},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1080/24725854.2020.1774688}}

@article{BBFNFMP2019closecentralclq,
	abstract = {Centrality is a powerful concept for detecting influential components of a network applicable to various areas such as analysis of social, collaboration, and biological networks. In this study, we employ one of the well-known centrality measures, closeness centrality, to detect a group of pairwise connected members (a highly connected community known as a clique) with the highest accessibility to the entire network. To measure the accessibility of a clique, we use two metrics, the maximum distance and the total distance to the clique from other members of the network. Hence, we are dealing with two variants of the most central clique problem referred to as maximum-distance-closeness-central clique and total-distance-closeness-central clique problems. We study the computational complexity of these two problems and prove that their decision versions are NP-complete. We also propose new mixed 0--1 integer programming formulations and the first combinatorial branch-and-bound algorithms to solve these problems exactly. We show that our algorithmic approaches offer at least 83-fold speed-up on over 96% of benchmark instances in comparison to existing approaches.},
	author = {Farzaneh Nasirian and Foad Mahdavi Pajouh and Balabhaskar Balasundaram},
	date-added = {2020-01-21 09:07:21 -0600},
	date-modified = {2020-01-21 09:08:29 -0600},
	doi = {https://doi.org/10.1016/j.ejor.2019.11.035},
	issn = {0377-2217},
	journal = {European Journal of Operational Research},
	keywords = {Networks, Closeness centrality, Clique, NP-completeness, Exact algorithms},
	month = {June},
	number = {2},
	pages = {461--475},
	title = {Detecting a most closeness-central clique in complex networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0377221719309464},
	volume = {283},
	year = {2020},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0377221719309464},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ejor.2019.11.035}}

@article{WebcoATP2013,
	abstract = {In this paper, we describe an application of prescriptive analytics to enhance data-driven decision making at a specialty steel bar products supplier and manufacturer in North America. As part of the company's daily business, it must make available-to-promise (ATP) decisions, which determine in real time the dates by which it can promise delivery of products that customers requested during the quotation stage. Previously, a salesperson had to make such decisions by analyzing reports on available inventory. To support these ATP decisions, we developed a real-time decision support system (DSS) to find an optimal assignment of the available inventory and to support additional what-if analysis. The DSS uses a suite of mixed-integer programming models and commercial software to solve the models. The company has incorporated the DSS into its enterprise resource planning system to seamlessly facilitate its use of business analytics. },
	author = {Mahdavi Pajouh , Foad and Xing, Dahai and Zhou, Yingjue and Hariharan, Sharethram and Balasundaram, Balabhaskar and Liu, Tieming and Sharda, Ramesh},
	date-added = {2019-06-26 18:12:58 -0500},
	date-modified = {2020-08-10 16:12:08 -0500},
	doi = {10.1287/inte.2013.0693},
	eprint = {https://doi.org/10.1287/inte.2013.0693},
	journal = {INFORMS Journal on Applied Analytics},
	number = {6},
	pages = {503-517},
	title = {A Specialty Steel Bar Company Uses Analytics to Determine Available-to-Promise Dates},
	url = {https://doi.org/10.1287/inte.2013.0693},
	volume = {43},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1287/inte.2013.0693}}

@article{BBSSZMCCkDomSNP2019,
	abstract = {Background High-throughput sequencing technology has revolutionized both medical and biological research by generating exceedingly large numbers of genetic variants. The resulting datasets share a number of common characteristics that might lead to poor generalization capacity. Concerns include noise accumulated due to the large number of predictors, sparse information regarding the p≫n problem, and overfitting and model mis-identification resulting from spurious collinearity. Additionally, complex correlation patterns are present among variables. As a consequence, reliable variable selection techniques play a pivotal role in predictive analysis, generalization capability, and robustness in clustering, as well as interpretability of the derived models.   Methods and findings K-dominating set, a parameterized graph-theoretic generalization model, was used to model SNP (single nucleotide polymorphism) data as a similarity network and searched for representative SNP variables. In particular, each SNP was represented as a vertex in the graph, (dis)similarity measures such as correlation coefficients or pairwise linkage disequilibrium were estimated to describe the relationship between each pair of SNPs; a pair of vertices are adjacent, i.e. joined by an edge, if the pairwise similarity measure exceeds a user-specified threshold. A minimum k-dominating set in the SNP graph was then made as the smallest subset such that every SNP that is excluded from the subset has at least k neighbors in the selected ones. The strength of k-dominating set selection in identifying independent variables, and in culling representative variables that are highly correlated with others, was demonstrated by a simulated dataset. The advantages of k-dominating set variable selection were also illustrated in two applications: pedigree reconstruction using SNP profiles of 1,372 Douglas-fir trees, and species delineation for 226 grasshopper mouse samples. A C++ source code that implements SNP-SELECT and uses Gurobi optimization solver for the k-dominating set variable selection is available (https://github.com/transgenomicsosu/SNP-SELECT).},
	author = {Shuzhen Sun and Zhuqi Miao and Blaise Ratcliffe and Polly Campbell and Bret Pasch and Yousry A. El-Kassaby and Balabhaskar Balasundaram and Charles Chen},
	date-added = {2019-01-29 08:42:50 -0600},
	date-modified = {2020-08-11 10:44:39 -0500},
	doi = {10.1371/journal.pone.0203242},
	journal = {{PLoS} ONE},
	month = {January},
	number = {1},
	pages = {1--18},
	publisher = {Public Library of Science},
	title = {{SNP} variable selection by generalized graph domination},
	url = {https://doi.org/10.1371/journal.pone.0203242},
	volume = {14},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pone.0203242}}

@article{BBEMkclubCHC2018,
	abstract = {Detecting low-diameter clusters is an important graph-based data mining technique used in social network analysis, bioinformatics and text-mining.  Low pairwise distances within a cluster can facilitate fast communication or good reachability between vertices in the cluster. Formally, a subset of vertices that induce a subgraph of diameter at most $k$ is called a $k$-club. For low values of the parameter $k$, this model offers a graph-theoretic relaxation of the clique model that formalizes the notion of a low-diameter cluster. Using a combination of graph decomposition and model decomposition techniques, we demonstrate how the fundamental optimization problem of finding a maximum size $k$-club can be solved optimally on large-scale benchmark instances that are available in the public domain. Our approach circumvents the use of complicated formulations of the maximum $k$-club problem in favor of a simple relaxation based on necessary conditions, combined with canonical hypercube cuts introduced by Balas and Jeroslow.},
	author = {Esmaeel Moradi and Balabhaskar Balasundaram},
	date-added = {2018-11-08 11:11:00 -0600},
	date-modified = {2020-08-10 15:53:29 -0500},
	doi = {10.1007/s11590-015-0971-7},
	journal = {Optimization Letters},
	month = {November},
	number = {8},
	pages = {1947--1957},
	title = {Finding a maximum $k$-club using the $k$-clique formulation and canonical hypercube cuts},
	url = {https://rdcu.be/b6a2W},
	volume = {12},
	year = {2018},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s11590-015-0971-7}}

@article{BBYLEMkclub2018CHCerr,
	abstract = {This article provides an erratum to ``Finding a maximum $k$-club using the $k$-clique formulation and canonical hypercube cuts,'' published online in Optim Lett, 2015. Due to  programming errors in our C++ implementations, the computational results reported in the article are incorrect. In some pathological instances, a significantly larger number of $k$-cliques that are not $k$-clubs can be detected, which can  adversely affect the performance of the algorithms proposed. This erratum presents completely revised computational results, discussion, and conclusions that are meant to \emph{replace} Sections~3 and~4 in the original article.

},
	author = {Yajun Lu and Esmaeel Moradi and Balabhaskar Balasundaram},
	date-added = {2018-11-08 11:11:00 -0600},
	date-modified = {2020-08-10 15:54:51 -0500},
	doi = {10.1007/s11590-018-1273-7},
	journal = {Optimization Letters},
	month = {November},
	number = {8},
	pages = {1959--1969},
	title = {Correction to: Finding a maximum $k$-club using the $k$-clique formulation and canonical hypercube cuts},
	url = {https://rdcu.be/b6a23},
	volume = {12},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/s11590-018-1273-7}}

@article{BBZM2020quasiclique,
	abstract = {A _$\gamma$-quasi-clique_ in a simple undirected graph refers to a subset of vertices that induces a subgraph with edge density at least $\gamma \\in [0,1]$. When $\gamma=1$, this definition corresponds to a classical clique. When $\gamma<1$, it relaxes the requirement of all possible edges by the clique  definition. Quasi-clique detection has been used in graph-based data mining to  find dense clusters, especially in large-scale error-prone data sets in which the clique model can be overly restrictive. The _maximum $\gamma$-quasi-clique problem_,  seeking a $\gamma$-quasi-clique of maximum cardinality in the given graph, can be formulated as an optimization problem with a linear objective function and a single quadratic constraint in binary variables. This article investigates the Lagrangian dual of this formulation, and develops an upper-bounding technique using the geometry of ellipsoids to bound the Lagrangian dual. The tightness of the upper-bound is compared to those obtained from multiple mixed-integer programming formulations of the problem via experiments on  benchmark instances.},
	author = {Zhuqi Miao and Balabhaskar Balasundaram},
	date-added = {2018-10-19 11:20:37 -0500},
	date-modified = {2020-12-23 10:50:22 -0600},
	doi = {10.1287/ijoc.2019.0922},
	journal = {{INFORMS} Journal on Computing},
	month = {August},
	number = {3},
	pages = {763--778},
	title = {An Ellipsoidal Bounding Scheme for the Quasi-Clique Number of a Graph},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2019.0922},
	volume = {32},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1287/ijoc.2019.0922}}

@article{BBJMCCPkcore2019,
	abstract = { A graph is called a $k$-core if every vertex has at least $k$ neighbors. If the parameter $k$ is sufficiently large relative to the number of vertices, a $k$-core is guaranteed to possess 2-hop reachability between all pairs of vertices. Furthermore, it is guaranteed to preserve those pairwise distances under arbitrary single-vertex deletion. Hence, the concept of a $k$-core can be used to produce 2-hop survivable network designs, specifically to design inter-hub networks.  Formally, given an edge-weighted graph, the minimum spanning $k$-core problem seeks a spanning subgraph of the given graph that is a $k$-core with minimum total edge weight. For any fixed $k$, this problem is equivalent to a generalized graph matching problem and can be solved in polynomial time. This article focuses on a chance-constrained version of the minimum spanning $k$-core problem under probabilistic edge failures. We first show that this probabilistic version is NP-hard, and we conduct a polyhedral study to strengthen the formulation. The quality of bounds produced by the strengthened formulation is demonstrated through a computational study.},
	author = {Juan Ma and Balabhaskar Balasundaram},
	date-added = {2018-10-10 10:26:39 -0500},
	date-modified = {2020-12-11 20:17:06 -0600},
	doi = {10.1007/s10898-018-0714-2},
	journal = {Journal of Global Optimization},
	month = {August},
	number = {4},
	pages = {783--801},
	title = {On the chance-constrained minimum spanning $k$-core problem},
	url = {https://rdcu.be/b6a2Y},
	volume = {74},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10898-018-0714-2}}

@article{BBFMZM2014quasiclique,
	abstract = {Detecting quasi-cliques in graphs is a useful tool for detecting dense clusters in graph-based data mining. Particularly in large-scale data sets that are  error-prone, cliques are overly restrictive and impractical. Quasi-clique detection has been accomplished using heuristic approaches  in various applications of graph-based data mining in protein interaction networks, gene co-expression networks,  and telecommunication networks. Quasi-cliques are not hereditary, in the sense that every subset of a quasi-clique need not be a quasi-clique. This lack of heredity introduces interesting challenges in the development of exact algorithms to detect maximum cardinality quasi-cliques. The only exact approaches for this problem are limited to two mixed integer programming formulations that were recently proposed in the literature. The main contribution of this article is  a new combinatorial branch-and-bound algorithm for the maximum quasi-clique problem.},
	author = {Foad Mahdavi Pajouh and Zhuqi Miao and Balabhaskar Balasundaram},
	date-modified = {2020-12-11 20:21:21 -0600},
	doi = {10.1007/s10479-012-1242-y},
	issn = {0254-5330},
	journal = {Annals of Operations Research},
	month = {May},
	number = {1},
	pages = {145--161},
	title = {A branch-and-bound approach for maximum quasi-cliques},
	url = {https://rdcu.be/b6a3b},
	volume = {216},
	year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10479-012-1242-y}}

@article{Slavik13kplex,
	abstract = {Given a simple undirected graph, the problem of finding a maximum subset of vertices satisfying a  \emph{nontrivial}, \emph{interesting} property $\Pi$ that is \emph{hereditary on induced subgraphs}, is known to be NP-hard. Many well-known graph properties meet the above conditions, making the problem widely applicable. This paper proposes a general purpose exact algorithmic framework to solve this problem and investigates key algorithm design and implementation issues that are helpful in tailoring the general framework for specific graph properties. The performance of the algorithms so derived for the \emph{maximum $s$-plex} and the \emph{maximum $s$-defective clique} problems, which arise in network-based data mining applications, is assessed through a computational study.},
	author = {Svyatoslav Trukhanov and Chitra Balasubramaniam and Balabhaskar Balasundaram and Sergiy Butenko},
	date-modified = {2020-08-10 16:03:05 -0500},
	doi = {10.1007/s10589-013-9548-5},
	journal = {Computational Optimization and Applications},
	month = {September},
	number = {1},
	pages = {113-130},
	title = {Algorithms for detecting optimal hereditary structures in graphs, with application to clique relaxations},
	url = {https://rdcu.be/b6a3d},
	volume = {56},
	year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10589-013-9548-5}}

@article{ZMBBEP2014JOCO,
	abstract = {The maximum clique problem is a classical problem in combinatorial optimization that has a broad range of applications in graph-based data mining, social and biological network analysis  and a variety of other fields. This article investigates the problem when the edges fail independently with known probabilities. This leads to the maximum probabilistic clique problem, which is to find a subset of vertices of maximum cardinality that forms a clique with probability at least $\theta$ in [0,1], which is a user-specified probability threshold. We show that the probabilistic clique property is hereditary and extend a well-known exact combinatorial algorithm for the maximum clique problem to a  sampling-free exact algorithm for the maximum probabilistic clique problem. The performance of the algorithm is benchmarked  on a test-bed of DIMACS clique instances and on a randomly generated test-bed.},
	author = {Zhuqi Miao and Balabhaskar Balasundaram and Eduardo L. Pasiliao},
	date-modified = {2020-12-11 20:53:35 -0600},
	doi = {10.1007/s10878-013-9699-4},
	journal = {Journal of Combinatorial Optimization},
	month = {July},
	number = {1},
	pages = {105--120},
	title = {An exact algorithm for the maximum probabilistic clique problem},
	url = {https://rdcu.be/b6a29},
	volume = {28},
	year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10878-013-9699-4}}

@article{BBZMkplexGRASP2017,
	abstract = {A $k$-plex is a clique relaxation introduced in social network analysis to model cohesive social subgroups that allows for a limited number of non-adjacent vertices (strangers) inside the cohesive subgroup.
Several exact algorithms and heuristic approaches to find a maximum-size $k$-plex in the graph have been developed recently for this NP-hard problem. This article develops a  \emph{greedy randomized adaptive search procedure} (GRASP) for the maximum $k$-plex problem. We offer a key improvement in the design of the construction procedure that alleviates a drawback observed in multiple past studies. In existing construction heuristics, $k$-plexes found for smaller values of parameter $k$ are sometimes not found for larger $k$ even though they are feasible; instead inferior solutions are found. We identify the reasons behind this behavior and address these in our new construction procedure. We then show that an existing exact algorithm for solving this problem on power-law graphs can be considerably enhanced by using GRASP. The overall approach is able to solve the problem to optimality on massive social networks, including some with several million vertices and edges. These are orders of magnitude larger than the largest real-life social networks on which this problem has been solved to optimality in the current literature.},
	author = {Zhuqi Miao and Balabhaskar Balasundaram},
	date-modified = {2020-08-10 15:55:32 -0500},
	doi = {10.1002/net.21745},
	journal = {Networks},
	month = {July},
	number = {4},
	pages = {388--407},
	title = {Approaches for finding cohesive subgroups in large-scale social networks via maximum $k$-plex detection},
	url = {http://dx.doi.org/10.1002/net.21745},
	volume = {69},
	year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/net.21745}}

@article{BBSCST10cokplxUDG,
	abstract = {This article studies a degree-bounded generalization of independent sets called co-$k$-plexes. Constant factor approximation algorithms are developed for the maximum co-$k$-plex problem on unit-disk graphs. The related problem of minimum co-$k$-plex coloring that generalizes classical vertex coloring is also studied in the context of unit-disk graphs. We extend several classical approximation results for independent sets in UDGs to co-$k$-plexes, and settle a recent conjecture on the approximability of co-$k$-plex coloring in UDGs.},
	author = {Balabhaskar Balasundaram and Shyam S. Chandramouli and Svyatoslav Trukhanov},
	date-modified = {2020-12-11 20:29:50 -0600},
	doi = {10.1007/s11590-009-0146-5},
	journal = {Optimization Letters},
	month = {August},
	number = {3},
	pages = {311-320},
	title = {Approximation algorithms for finding and partitioning unit-disk graphs into co-$k$-plexes},
	url = {https://rdcu.be/b6a3p},
	volume = {4},
	year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1007/s11590-009-0146-5}}

@article{BBSBIVH11kplex,
	abstract = {This paper introduces and studies the maximum $k$-plex problem, which arises in social network analysis and has wider applicability in several important areas employing graph-based data mining. After establishing NP-completeness of the decision version of the problem on arbitrary graphs, an integer programming formulation is presented, followed by a polyhedral study to identify combinatorial valid inequalities and facets. A branch-and-cut algorithm is implemented and tested on proposed benchmark instances. An algorithmic approach is developed exploiting the graph-theoretic properties of a $k$-plex that is effective in solving the problem to optimality on very large, sparse graphs such as the power law graphs frequently encountered in the applications of interest. },
	author = {Balabhaskar Balasundaram and Sergiy Butenko and Illya V. Hicks},
	date-modified = {2020-12-11 20:29:14 -0600},
	doi = {https://doi.org/10.1287/opre.1100.0851},
	journal = {Operations Research},
	month = {January-February},
	number = {1},
	pages = {133--142},
	title = {Clique relaxations in social network analysis: {T}he maximum $k$-plex problem},
	url = {10.1287/opre.1100.0851},
	volume = {59},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1287/opre.1100.0851}}

@inproceedings{BBZMiserc2012,
	abstract = {Cliques have long been the standardmodel for cluster detection in graph-based datamining. However, clique definition is overly restrictive making the approach unsuitable for real-life networks that are constructed based on erroneous or incomplete data. A parameterized clique relaxation called a $k$-plex that overcomes this drawback was introduced in social network analysis for detecting cohesive social subgroups. Several exact algorithms for the maximum $k$-plex problem were recently developed. However, heuristic approaches which are more suitable for the analysis of largescale social networks are unavailable. This article develops an effective greedy randomized adaptive search procedure (GRASP) and compares its performance on standard benchmarks against integer programming heuristics available in a well-known commercial solver. More significantly, this article demonstrates that an exact algorithm for solving this problem on power-law graphs can be considerably enhanced by using GRASP, so that the combination is able to solve the problem to optimality on much larger social networks than previously known.},
	address = {Norcross, GA},
	author = {Zhuqi Miao and Balabhaskar Balasundaram},
	booktitle = {Proceedings of the 2012 Industrial and Systems Engineering Research Conference (ISERC 2012)},
	date-modified = {2020-12-11 20:28:15 -0600},
	pages = {1--10},
	publisher = {Institute of Industrial Engineers},
	title = {Cluster detection in large-scale social networks using $k$-plexes},
	url = {https://search.proquest.com/docview/1151089542},
	year = {2012},
	Bdsk-Url-1 = {https://search.proquest.com/docview/1151089542}}

@inproceedings{BB08case,
	abstract = {A $k$-plex is a graph theoretic generalization of a clique, introduced in social network analysis (SNA) to model tightly knit social subgroups referred to as cohesive subgroups. Clique model was the earliest mathematical model for a cohesive subgroup, but its overly restrictive definition motivated several relaxations including the $k$-plex model. The models from SNA are suitable, and potentially more realistic cluster models for graph-based clustering and data mining. This article will discuss the applicability of the $k$-plex model and its advantages compared to the clique model. Some recent developments in integer programming based approaches to identify large $k$-plexes would be described and the approaches demonstrated on a text mining network.},
	author = {Balabhaskar Balasundaram},
	booktitle = {Proceedings of the 2008 {IEEE} International Conference on Automation Science and Engineering (CASE 2008)},
	date-modified = {2020-12-11 20:32:00 -0600},
	doi = {10.1109/COASE.2008.4626551},
	month = {August},
	pages = {989--994},
	publisher = {IEEE},
	title = {Cohesive subgroup model for graph-based text mining},
	url = {https://doi.org/10.1109/COASE.2008.4626551},
	year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/COASE.2008.4626551}}

@article{BBSB05testing,
	abstract = {A method for constructing test functions for global optimization which utilizes continuous formulations of combinatorial optimization problems is suggested. In particular, global optimization formulations for the maximum independent set, maximum clique, and MAX CUT problems on arbitrary graphs are considered, and proofs for some of them are given. A number of sample test functions based on these formulations are proposed.},
	author = {Balabhaskar Balasundaram and Sergiy Butenko},
	date-modified = {2020-08-10 16:25:47 -0500},
	doi = {10.1080/10556780500139641},
	journal = {Journal of Optimization Methods and Software},
	month = {August-October},
	number = {4-5},
	pages = {439--452},
	title = {Constructing Test Functions for Global Optimization Using Continuous Formulations of Graph Problems},
	url = {https://doi.org/10.1080/10556780500139641},
	volume = {20},
	year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1080/10556780500139641}}

@article{BBFMEM2clubcvar2016,
	abstract = {Detecting large 2-clubs in biological, social and financial networks can help reveal important information about  the structure of the underlying systems. In large-scale networks that are error-prone, the uncertainty associated with the existence of an edge between two vertices can be modeled by assigning a failure probability to that edge. Here, we study the problem of detecting large ``risk-averse'' 2-clubs in graphs subject to probabilistic edge failures. To achieve risk aversion, we first model the loss in 2-club property due to probabilistic edge failures as a function of the decision (chosen 2-club cluster) and randomness (graph structure). Then, we utilize the conditional value-at-risk (CVaR) of the loss for a given decision as a quantitative measure of risk for that decision, which is bounded in the model. More precisely, the problem is modeled as a CVaR-constrained single-stage stochastic program. The main contribution of this article is a new decomposition algorithm based on a Benders decomposition scheme, which outperforms an algorithm based on an existing decomposition idea, on a test-bed of randomly generated instances, and real-life biological and social networks.},
	author = {Foad Mahdavi Pajouh and Esmaeel Moradi and Balabhaskar Balasundaram},
	date-modified = {2020-08-10 15:56:56 -0500},
	doi = {10.1007/s10479-016-2279-0},
	journal = {Annals of Operations Research},
	month = {February},
	number = {1},
	pages = {55--73},
	title = {Detecting large risk-averse 2-clubs in graphs with random edge failures},
	url = {https://rdcu.be/b6a25},
	volume = {249},
	year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10479-016-2279-0}}

@incollection{BBFM2011EORMS,
	abstract = {The gradient method , which is also called the method of steepest descent, and the Cauchy method, is one of the most fundamental derivative‐based procedure for unconstrained minimization of a differentiable function. The performance of the method in terms of speed of convergence is lacking, and it tends to suffer from very slow convergence, especially as a stationary point is approached. However, it does guarantee global convergence under reasonable conditions and admits a thorough mathematical analysis of its behavior. For this reason, the gradient method has been used as a starting point in the development of more sophisticated, globally convergent algorithms with better convergence properties for unconstrained minimization. This article presents a cogent overview of this fundamental method and its convergence properties under various settings.},
	author = {Foad Mahdavi Pajouh and Balabhaskar Balasundaram},
	booktitle = {Wiley Encyclopedia of Operations Research and Management Science},
	date-modified = {2020-08-10 16:15:55 -0500},
	doi = {10.1002/9780470400531.eorms0363},
	editor = {Cochran, J. J. and Cox, L. A. and Keskinocak, P. and Kharoufeh, J. P. and Smith, J. C.},
	isbn = {9780470400531},
	keywords = {unconstrained optimization, gradient method, method of steepest descent, Cauchy method, subgradient method},
	pages = {2092--2099},
	publisher = {John Wiley \& Sons, Inc.},
	title = {Gradient-Type Methods},
	url = {http://dx.doi.org/10.1002/9780470400531.eorms0363},
	volume = {3},
	year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/9780470400531.eorms0363}}

@incollection{BBSB06telesurvey,
	abstract = {This chapter aims to provide a detailed survey of existing graph models and algorithms for important problems that arise in different areas of wireless telecommunication. In particular, applications of graph optimization problems such as minimum dominating set, minimum vertex coloring and maximum clique in multihop wireless networks are discussed. Different forms of graph domination have been used extensively to model clustering in wireless ad hoc networks. Graph coloring problems and their variants have been used to model channel assignment and scheduling type problems in wireless networks. Cliques are used to derive bounds on chromatic number, and are used in models of traffic flow, resource allocation, interference, etc. In this chapter we survey the solution methods proposed in the literature for these problems and some recent theoretical results that are relevant to this area of research in wireless networks.},
	address = {New York},
	author = {Balabhaskar Balasundaram and Sergiy Butenko},
	booktitle = {Handbook of Optimization in Telecommunications},
	date-modified = {2020-08-10 16:24:27 -0500},
	doi = {10.1007/978-0-387-30165-5_30},
	editor = {M. G. C. Resende and P. M. Pardalos},
	pages = {865-890},
	publisher = {Springer Science + Business Media},
	title = {Graph domination, coloring and cliques in telecommunications},
	url = {https://doi.org/10.1007/978-0-387-30165-5_30},
	year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-0-387-30165-5_30}}

@incollection{BBFM2013HBCO,
	abstract = {Cliques and graph theoretic clique relaxations are used to model clusters in graph-based data mining, where data is modeled by a graph in which an edge implies some relationship between the entities represented by its endpoints. The need for relaxations of the clique model arises in practice when dealing with massive data sets which are error-prone, resulting in false or missing edges. The clique definition which requires complete pairwise adjacency in the cluster becomes overly restrictive in such situations. Graph theoretic clique relaxations address this need by relaxing  structural properties of a clique in a controlled manner via user-specified parameters. This chapter surveys such  clique relaxations available in the literature primarily focussing on polyhedral results, complexity studies, approximability, and exact algorithmic approaches.},
	address = {New York},
	author = {Balabhaskar Balasundaram and Foad Mahdavi Pajouh},
	booktitle = {Handbook of Combinatorial Optimization},
	date-modified = {2020-12-11 20:25:33 -0600},
	doi = {https://doi.org/10.1007/978-1-4419-7997-1_9},
	edition = {2nd},
	editor = {P. M. Pardalos and D.-Z. Du and R. Graham},
	isbn = {978-1-4419-7996-4},
	pages = {1559-1598},
	publisher = {Springer},
	title = {Graph theoretic clique relaxations and applications},
	url = {https://doi.org/10.1007/978-1-4419-7997-1_9},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-1-4419-7997-1_9}}

@phdthesis{BB07thesis,
	abstract = {This dissertation considers graph theoretic
generalizations of the maximum clique problem. Models that
were originally proposed in social network analysis
literature, are investigated from a mathematical programming
perspective for the first time. A social network is usually
represented by a graph, and cliques were the first models of
``tightly knit groups'' in social networks, referred to as
cohesive subgroups. Cliques are idealized models and their
overly restrictive nature motivated the development of clique
relaxations that relax different aspects of a clique. Identifying
large cohesive subgroups in social networks has traditionally been used in criminal network analysis to study organized crimes such as terrorism, narcotics and money laundering. More recent applications are in clustering and data mining wireless networks, biological networks as well as graph models of databases and the internet. This research has the potential to impact homeland security, bioinformatics, internet research and telecommunication industry among others.

The focus of this dissertation is a degree-based relaxation called
$k$-plex. A distance-based relaxation called
$k$-clique and a diameter-based relaxation called
$k$-club are also investigated in this dissertation. We
present the first systematic study of the complexity aspects of
these problems and application of mathematical programming
techniques in solving them. Graph theoretic properties of the models
are identified and used in the development of theory and algorithms.

Optimization problems associated with the three models are
formulated as binary integer programs and the properties of the
associated polytopes are investigated. Facets and valid inequalities
are identified based on combinatorial arguments. A branch-and-cut
framework is designed and implemented to solve the optimization
problems exactly. Specialized preprocessing techniques are developed
that, in conjunction with the branch-and-cut algorithm, optimally
solve the problems on real-life power law graphs, which is a
general class of graphs that include social and biological networks.
Computational experiments are performed to study the effectiveness
of the proposed solution procedures on benchmark instances and
real-life instances.

The relationship of these models to the classical maximum clique
problem is studied, leading to several interesting observations
including a new compact integer programming formulation. We also
prove new continuous non-linear formulations for the classical
maximum independent set problem which maximize continuous functions
over the unit hypercube, and characterize its local and global
maxima. Finally, clustering and network design extensions of the
clique relaxation models are explored.},
	address = {College Station, Texas, USA},
	author = {Balabhaskar Balasundaram},
	date-modified = {2020-12-11 20:33:56 -0600},
	school = {Texas A\&M University},
	title = {Graph Theoretic Generalizations Of Clique: {O}ptimization and Extensions},
	url = {https://search.proquest.com/docview/304727446/},
	year = {2007},
	Bdsk-Url-1 = {https://search.proquest.com/docview/304727446/}}

@inproceedings{BBGSVK2001msd,
	address = {Mumbai},
	author = {G. Srinivasan and B. Balasundaram and V. Karthik},
	booktitle = {Proceedings of the Ist International Conference on Logistics and Supply Chain Management},
	date-modified = {2020-08-10 16:26:20 -0500},
	editor = {P. Radhakrishnan and S. Palaniswami and P. V. Mohanram and J. Kanchana},
	month = {August},
	pages = {234--239},
	publisher = {Allied Publishers},
	title = {Minimizing squared deviation of completion times about a common due date - algorithms and heuristics},
	url = {https://books.google.com/books?id=AvheqE0D8ZIC&lpg=PP1&dq=8177641859&pg=PP1#v=onepage&q&f=false},
	year = {2001},
	Bdsk-Url-1 = {https://books.google.com/books?id=AvheqE0D8ZIC&lpg=PP1&dq=8177641859&pg=PP1#v=onepage&q&f=false}}

@inproceedings{BBPSMK2009icovacs,
	author = {Peerapol Sittivijan and Manjunath Kamath and Balabhaskar Balasundaram},
	booktitle = {Proceedings of the 2009 International Conference on Value Chain Sustainability (ICOVACS 2009)},
	date-modified = {2019-04-24 17:15:37 -0500},
	pages = {32--37},
	title = {Models for clustering commodities into logistical families},
	year = {2009}}

@incollection{BBSB08ntwkclustering,
	address = {New York},
	author = {Balabhaskar Balasundaram and Sergiy Butenko},
	booktitle = {Analysis of Biological Networks},
	date-modified = {2020-08-10 16:21:58 -0500},
	doi = {10.1002/9780470253489.ch6},
	editor = {B. H. Junker and F. Schreiber},
	pages = {113-138},
	publisher = {Wiley},
	title = {Network Clustering},
	url = {https://doi.org/10.1002/9780470253489.ch6},
	year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1002/9780470253489.ch6}}

@article{BBSB05bionet,
	abstract = {This paper proposes clique relaxations to identify clusters in biological networks. In particular, the maximum $n$-clique and maximum $n$-club problems on an arbitrary graph are introduced and their recognition versions are shown to be NP-complete. In addition, integer programming formulations are proposed and the results of sample numerical experiments performed on biological networks are reported.},
	author = {Balabhaskar Balasundaram and Sergiy Butenko and Svyatoslav Trukhanov},
	date-modified = {2020-12-11 20:36:58 -0600},
	doi = {10.1007/s10878-005-1857-x},
	journal = {Journal of Combinatorial Optimization},
	month = {August},
	number = {1},
	pages = {23-39},
	title = {Novel approaches for analyzing biological networks},
	url = {https://rdcu.be/b6a3D},
	volume = {10},
	year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10878-005-1857-x}}

@article{BBSB06localmax,
	abstract = {In this paper we characterize the local maxima of a continuous global optimization formulation for finding the independence number of a graph. Classical Karush-Kuhn-Tucker conditions and simple combinatorial arguments are found sufficient to deduce several interesting properties of the local and global maxima. These properties can be utilized in developing new approaches to the maximum independent set problem.},
	author = {Balabhaskar Balasundaram and Sergiy Butenko},
	date-modified = {2020-08-10 16:23:49 -0500},
	doi = {10.1007/s10898-005-5185-6},
	journal = {Journal of Global Optimization},
	month = {July},
	number = {3},
	pages = {405--421},
	title = {On a polynomial fractional formulation for independence number of a graph},
	url = {https://rdcu.be/b6a3z},
	volume = {35},
	year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10898-005-5185-6}}

@article{BBFMOP2013qubo,
	abstract = {This article investigates the local maxima properties of a box-constrained quadratic optimization formulation of the
maximum independent set problem in graphs. Theoretical results characterizing binary local maxima in terms of certain
induced subgraphs of the given graph are developed. We also consider relations between continuous local maxima of the
quadratic formulation and binary local maxima in the Hamming distance-1 and distance-2 neighborhoods. These results are
then used to develop an efficient local search algorithm that provides considerable speed-up over a typical local
search algorithm for the binary Hamming distance-2 neighborhood.},
	author = {Foad Mahdavi Pajouh and Balabhaskar Balasundaram and Oleg A. Prokopyev},
	date-modified = {2020-08-10 16:06:00 -0500},
	doi = {10.1007/s10732-011-9171-5},
	journal = {Journal of Heuristics},
	month = {August},
	number = {4},
	pages = {629--644},
	title = {On characterization of maximal independent sets via quadratic optimization},
	url = {https://rdcu.be/b6a3h},
	volume = {19},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10732-011-9171-5}}

@article{BBFM2012kclub,
	abstract = {A $k$-club is a distance-based graph-theoretic generalization of a clique, originally introduced to model cohesive social subgroups in social network analysis. The $k$-clubs represent low diameter clusters in graphs and are appropriate for various graph-based data mining applications. Unlike cliques, the $k$-club model is nonhereditary, meaning every subset of a $k$-club is not necessarily a $k$-club. In this article, we settle an open problem establishing the intractability of testing inclusion-wise maximality of $k$-clubs. This result is in contrast to polynomial-time verifiability of maximal cliques, and is a direct consequence of its nonhereditary nature. We also identify a class of graphs for which this problem is polynomial-time solvable. We propose a distance coloring based upper-bounding scheme and a bounded enumeration based lower-bounding routine and employ them in a combinatorial branch-and-bound algorithm for finding maximum cardinality $k$-clubs. Computational results from using the proposed algorithms on 200-vertex graphs are also provided.},
	author = {Foad Mahdavi Pajouh and Balabhaskar Balasundaram},
	date-modified = {2020-12-11 20:27:10 -0600},
	doi = {https://doi.org/10.1016/j.disopt.2012.02.002},
	journal = {Discrete Optimization},
	month = {May},
	number = {2},
	pages = {84--97},
	title = {On inclusionwise maximal and maximum cardinality $k$-clubs in graphs},
	url = {http://www.sciencedirect.com/science/article/pii/S1572528612000163},
	volume = {9},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.disopt.2012.02.002}}

@article{BBFMIVH2club2016,
	abstract = {A $k$-club is a subset of vertices of a graph that induces a subgraph of diameter at most $k$, where $k$ is a positive integer. By definition, 1-clubs are cliques and the model is a distance-based relaxation of the clique definition for larger values of $k$. The $k$-club model  is particularly interesting to study from a polyhedral perspective as the property is not hereditary on induced subgraphs when $k$ is larger than one. This article introduces a new family of facet-defining inequalities for the 2-club polytope that unifies all previously known facets through a less restrictive combinatorial property, namely independent (distance) 2-domination. The complexity of separation over this new family of inequalities is shown to be NP-hard. An exact formulation of this separation problem and a greedy separation heuristic are also proposed. The polytope described by the new inequalities (and nonnegativity) is then investigated and   shown to be  integral for acyclic graphs. An additional family of facets are also demonstrated for cycles of length indivisible by 3. The effectiveness of these new facets as cutting planes, and the difficulty of solving the separation problem in practice are then investigated via computational experiments on a test-bed of benchmark instances.},
	author = {Foad Mahdavi Pajouh and Balabhaskar Balasundaram and Illya V. Hicks},
	date-modified = {2020-08-10 15:58:14 -0500},
	doi = {10.1287/opre.2016.1500},
	journal = {Operations Research},
	month = {November-December},
	number = {6},
	pages = {1466--1481},
	title = {On the 2-club polytope of graphs},
	url = {http://dx.doi.org/10.1287/opre.2016.1500},
	volume = {64},
	year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1287/opre.2016.1500}}

@incollection{BBSB09UDG,
	address = {New York},
	author = {Balabhaskar Balasundaram and Sergiy Butenko},
	booktitle = {Encyclopedia of Optimization},
	date-modified = {2020-08-10 16:18:46 -0500},
	doi = {10.1007/978-0-387-74759-0_486},
	edition = {2nd},
	editor = {C. A. Floudas and P. M. Pardalos},
	pages = {2832-2844},
	publisher = {Springer Science + Business Media},
	title = {Optimization problems in unit-disk graphs},
	url = {https://doi.org/10.1007/978-0-387-74759-0_486},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-0-387-74759-0_486}}

@article{Grout2012,
	abstract = {Exceptionally severe winter storms that overwhelm local government result in major disaster declarations. Each National Weather Service forecast office in the United States reports winter events for a specific group of counties, known as the county warning area. Such events are reported as blizzard, ice storm, winter storm, heavy snow, or winter weather. They are archived by the National Climatic Data Center and are published in Storm Data, a monthly periodical. Using Storm Data, all winter reports in Oklahoma from 1 November 1999 to 1 May 2010 were compiled into a database. The results of this study demonstrated that while counties in northern Oklahoma received the highest number of winter reports, when compared with climatology winter storm, heavy snow, ice storm, and blizzard storm types yielded an above-average occurrence across much of southwest and central Oklahoma over the study period.

Disaster information, obtained from the Federal Emergency Management Agency, showed that from 1 November 1999 to 1 May 2010 Oklahoma led the nation with nine winter-related federal disasters, resulting in nearly $800 million (U.S. dollars) in federal aid. High-impact events, determined by disaster declarations, were most frequent across southwest, central, and northeast Oklahoma, and southwest Oklahoma experienced a disaster nearly every third winter event. Over much of Oklahoma, ice storms were more likely to result in a disaster than winter storm, blizzard, and heavy snow events combined. Spatial distributions of federal aid showed that rural counties were most impacted by the winter weather disasters and required greater federal assistance.},
	author = {Trevor Grout and Yang Hong and Jeffrey Basara and Balabhaskar Balasundaram and Zhenyu Kong and Satish T. S. Bukkapatnam},
	date-modified = {2020-08-10 16:14:23 -0500},
	doi = {10.1175/WCAS-D-11-00057.1},
	journal = {Weather, Climate, and Society},
	month = {January},
	number = {1},
	pages = {48--58},
	title = {Significant Winter Weather Events and Associated Socioeconomic Impacts (Federal Aid Expenditures) across {Oklahoma}: 2000-2010},
	url = {https://doi.org/10.1175/WCAS-D-11-00057.1},
	volume = {4},
	year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1175/WCAS-D-11-00057.1}}

@inproceedings{BBJMiserc2013,
	abstract = {Given a non-negative integer $k$, a graph of minimum degree at least $k$ is called a $k$-core. The concept of $k$-cores can be used to design resilient networks that preserve low diameter and high vertex-connectivity upon limited vertex or edge failures. This article focuses on a chance-constrained version of the minimum spanning $k$-core problem under probabilistic edge failures. Specifically, given that the edges can fail randomly and independently, we want to find a subset of edges of minimum total cost such that the graph with this edge set is a $k$-core with probability at least $1-\alpha$ where $\alpha$ in [0,1]. We first reformulate the non-convex chance-constrained optimization problem as a large-scale integer program. To solve it, we employ  a decomposition and branch-and-cut framework recently introduced in the literature and discuss problem-specific enhancements of this approach. We report on our computational experiments designed to benchmark this decomposition branch-and-cut algorithm.},
	address = {Norcross, GA},
	author = {Juan Ma and Balabhaskar Balasundaram},
	booktitle = {Proceedings of the 2013 Industrial and Systems Engineering Research Conference (ISERC 2013)},
	date-modified = {2020-12-11 20:54:16 -0600},
	pages = {2774--2783},
	publisher = {Institute of Industrial Engineers},
	title = {Solving chance-constrained spanning $k$-core problem via decomposition and integer programming},
	url = {https://search.proquest.com/docview/1471961684},
	year = {2013},
	Bdsk-Url-1 = {https://search.proquest.com/docview/1471961684}}

@article{BBJMFMVBkcore2015,
	abstract = {This article introduces the minimum spanning $k$-core problem that seeks to find a spanning subgraph with minimum degree at least $k$ (also known as a $k$-core) that minimizes the total cost of the edges in the subgraph.  The concept of $k$-cores was introduced in social network analysis to identify denser portions of a social network. We exploit the graph-theoretic properties of this model to introduce a new approach to survivable inter-hub network design via spanning $k$-cores that preserves connectivity and diameter under limited edge failures. The deterministic version of the problem is polynomial-time solvable due to its equivalence to generalized graph matching. We propose two conditional value-at-risk (CVaR) constrained optimization models to obtain risk-averse solutions for the minimum spanning $k$-core problem under probabilistic edge failures. We present polyhedral reformulations of the convex piecewise linear loss functions used in these models that enable Benders-like decomposition approaches. A decomposition and branch-and-cut approach is then developed to solve the scenario-based approximation of the CVaR-constrained minimum spanning $k$-core problem for the aforementioned loss functions. The computational performance of the algorithm is investigated via numerical experiments.},
	author = {Juan Ma and Foad Mahdavi Pajouh and Balabhaskar Balasundaram and Vladimir Boginski},
	date-modified = {2020-12-11 20:19:38 -0600},
	doi = {10.1287/ijoc.2015.0679},
	journal = {INFORMS Journal on Computing},
	month = {April},
	number = {2},
	pages = {295--307},
	title = {The minimum spanning $k$-core problem with bounded {CVaR} under probabilistic edge failures},
	url = {http://dx.doi.org/10.1287/ijoc.2015.0679},
	volume = {28},
	year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1287/ijoc.2015.0679}}

@article{BBMarcoDIS2013,
	abstract = {One way to achieve reliability with low-latency is through multi-path routing and transport protocols that build redundant delivery channels (or data paths) to reduce end-to-end packet losses and retransmissions. However, the applicability and effectiveness of such protocols are limited by the topological constraints of the underlying communication infrastructure. Multiple data delivery paths can only be constructed over networks that are capable of supporting multiple paths. In mission-critical wireless networks, the underlying network topology is directly affected by the terrain, location and environmental interferences, however the settings of the wireless radios at each node can be properly configured to compensate for these effects for multi-path support. In this work we investigate optimization models for topology designs that enable end-to-end dual-path support on a distributed wireless sensor network. We consider the case of a fixed sensor network with isotropic antennas, where the control variable for topology management is the transmission power on network nodes.  For optimization modeling, the network metrics of relevance are coverage, robustness and power utilization. The optimization models proposed in this work eliminate some of the typical assumptions made in the pertinent network design literature that are too strong in this application context.},
	author = {Marco Carvalho and Alexey Sorokin and Vladimir Boginski and Balabhaskar Balasundaram},
	date-modified = {2020-08-10 16:07:14 -0500},
	doi = {10.1007/s11590-012-0453-0},
	journal = {Optimization Letters},
	month = {April},
	number = {4},
	pages = {695--707},
	title = {Topology Design for On-Demand Dual-Path Routing in Wireless Networks},
	url = {https://rdcu.be/b6a3j},
	volume = {7},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/s11590-012-0453-0}}

@article{BBSBOY2013vos,
	abstract = {This paper introduces the variable objective search framework for combinatorial optimization. The method utilizes different objective functions used in alternative mathematical programming formulations of the same combinatorial optimization problem in an attempt to improve the solutions obtained using each of these formulations individually. The proposed technique is illustrated using alternative quadratic unconstrained binary formulations of the classical maximum independent set problem in graphs.},
	author = {Sergiy Butenko and Oleksandra Yezerska and Balabhaskar Balasundaram},
	date-modified = {2020-08-10 16:04:56 -0500},
	doi = {10.1007/s10732-011-9174-2},
	journal = {Journal of Heuristics},
	month = {August},
	number = {4},
	pages = {697-709},
	title = {Variable Objective Search},
	url = {https://rdcu.be/b6a3f},
	volume = {19},
	year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10732-011-9174-2}}
